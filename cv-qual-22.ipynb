{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":323819,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":272793,"modelId":293767}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"fb60650e","cell_type":"code","source":"import torch\nimport torchvision.transforms as T\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport qai_hub as hub\nfrom torchcam.methods import GradCAM\nimport segmentation_models_pytorch as smp\nimport torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T17:25:54.484229Z","iopub.execute_input":"2025-04-06T17:25:54.484554Z","iopub.status.idle":"2025-04-06T17:25:58.794854Z","shell.execute_reply.started":"2025-04-06T17:25:54.484525Z","shell.execute_reply":"2025-04-06T17:25:58.794210Z"}},"outputs":[],"execution_count":6},{"id":"f71eb06d","cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = smp.UnetPlusPlus(\n            encoder_name='timm-mobilenetv3_small_100',\n            encoder_weights='imagenet',\n            in_channels=3,\n            classes=1  # Outputting a single channel for depth map\n        )\n        \n    def trainable_encoder(self, trainable=True):\n        for p in self.model.encoder.parameters():\n            p.requires_grad = trainable\n        \n    def forward(self, x):\n        return self.model(x)\n    \n    def _num_params(self):\n        return sum([p.numel() for p in self.model.parameters() if p.requires_grad])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T17:26:52.319217Z","iopub.execute_input":"2025-04-06T17:26:52.319501Z","iopub.status.idle":"2025-04-06T17:26:52.324890Z","shell.execute_reply.started":"2025-04-06T17:26:52.319480Z","shell.execute_reply":"2025-04-06T17:26:52.323933Z"}},"outputs":[],"execution_count":8},{"id":"f926bf15-77f0-4d19-ba2c-a4c0116fab2c","cell_type":"code","source":"import os\n\nprint(os.listdir('/kaggle/input/cvt1/pytorch/default/1'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T17:29:36.049026Z","iopub.execute_input":"2025-04-06T17:29:36.049381Z","iopub.status.idle":"2025-04-06T17:29:36.053990Z","shell.execute_reply.started":"2025-04-06T17:29:36.049354Z","shell.execute_reply":"2025-04-06T17:29:36.053147Z"}},"outputs":[{"name":"stdout","text":"['nyu-v2-depth-mobilenet-unetplusplus.pt']\n","output_type":"stream"}],"execution_count":11},{"id":"21632e7a","cell_type":"code","source":"import torch\nfrom collections import OrderedDict\n\n# Define your UNet model\nunet_model = UNet().to('cuda')\n\n# Load the state dictionary from the checkpoint file\nstate_dict = torch.load('/kaggle/input/cvt1/pytorch/default/1/nyu-v2-depth-mobilenet-unetplusplus.pt', map_location='cuda')\n\n# Remove \"module.\" prefix if present\nnew_state_dict = OrderedDict()\nfor k, v in state_dict.items():\n    new_key = k.replace(\"module.\", \"\")\n    new_state_dict[new_key] = v\n\n# Load the state dict into the model\nunet_model.load_state_dict(new_state_dict)\nunet_model.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T17:30:15.408639Z","iopub.execute_input":"2025-04-06T17:30:15.408922Z","iopub.status.idle":"2025-04-06T17:30:15.993955Z","shell.execute_reply.started":"2025-04-06T17:30:15.408902Z","shell.execute_reply":"2025-04-06T17:30:15.993156Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-12-7ac3c5624b2e>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load('/kaggle/input/cvt1/pytorch/default/1/nyu-v2-depth-mobilenet-unetplusplus.pt', map_location='cuda')\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"UNet(\n  (model): UnetPlusPlus(\n    (encoder): MobileNetV3Encoder(\n      (model): MobileNetV3Features(\n        (conv_stem): Conv2dSame(3, 16, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn1): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): Hardswish()\n        (blocks): Sequential(\n          (0): Sequential(\n            (0): DepthwiseSeparableConv(\n              (conv_dw): Conv2dSame(16, 16, kernel_size=(3, 3), stride=(2, 2), groups=16, bias=False)\n              (bn1): BatchNormAct2d(\n                16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): ReLU(inplace=True)\n              )\n              (aa): Identity()\n              (se): SqueezeExcite(\n                (conv_reduce): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n                (act1): ReLU(inplace=True)\n                (conv_expand): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n                (gate): Hardsigmoid()\n              )\n              (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn2): BatchNormAct2d(\n                16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Identity()\n              )\n              (drop_path): Identity()\n            )\n          )\n          (1): Sequential(\n            (0): InvertedResidual(\n              (conv_pw): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): BatchNormAct2d(\n                72, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): ReLU(inplace=True)\n              )\n              (conv_dw): Conv2dSame(72, 72, kernel_size=(3, 3), stride=(2, 2), groups=72, bias=False)\n              (bn2): BatchNormAct2d(\n                72, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): ReLU(inplace=True)\n              )\n              (aa): Identity()\n              (se): Identity()\n              (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): BatchNormAct2d(\n                24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Identity()\n              )\n              (drop_path): Identity()\n            )\n            (1): InvertedResidual(\n              (conv_pw): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): BatchNormAct2d(\n                88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): ReLU(inplace=True)\n              )\n              (conv_dw): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n              (bn2): BatchNormAct2d(\n                88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): ReLU(inplace=True)\n              )\n              (aa): Identity()\n              (se): Identity()\n              (conv_pwl): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): BatchNormAct2d(\n                24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Identity()\n              )\n              (drop_path): Identity()\n            )\n          )\n          (2): Sequential(\n            (0): InvertedResidual(\n              (conv_pw): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): BatchNormAct2d(\n                96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (conv_dw): Conv2dSame(96, 96, kernel_size=(5, 5), stride=(2, 2), groups=96, bias=False)\n              (bn2): BatchNormAct2d(\n                96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (aa): Identity()\n              (se): SqueezeExcite(\n                (conv_reduce): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n                (act1): ReLU(inplace=True)\n                (conv_expand): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n                (gate): Hardsigmoid()\n              )\n              (conv_pwl): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): BatchNormAct2d(\n                40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Identity()\n              )\n              (drop_path): Identity()\n            )\n            (1): InvertedResidual(\n              (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): BatchNormAct2d(\n                240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n              (bn2): BatchNormAct2d(\n                240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (aa): Identity()\n              (se): SqueezeExcite(\n                (conv_reduce): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n                (act1): ReLU(inplace=True)\n                (conv_expand): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n                (gate): Hardsigmoid()\n              )\n              (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): BatchNormAct2d(\n                40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Identity()\n              )\n              (drop_path): Identity()\n            )\n            (2): InvertedResidual(\n              (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): BatchNormAct2d(\n                240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n              (bn2): BatchNormAct2d(\n                240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (aa): Identity()\n              (se): SqueezeExcite(\n                (conv_reduce): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n                (act1): ReLU(inplace=True)\n                (conv_expand): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n                (gate): Hardsigmoid()\n              )\n              (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): BatchNormAct2d(\n                40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Identity()\n              )\n              (drop_path): Identity()\n            )\n          )\n          (3): Sequential(\n            (0): InvertedResidual(\n              (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): BatchNormAct2d(\n                120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n              (bn2): BatchNormAct2d(\n                120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (aa): Identity()\n              (se): SqueezeExcite(\n                (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n                (act1): ReLU(inplace=True)\n                (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n                (gate): Hardsigmoid()\n              )\n              (conv_pwl): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): BatchNormAct2d(\n                48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Identity()\n              )\n              (drop_path): Identity()\n            )\n            (1): InvertedResidual(\n              (conv_pw): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): BatchNormAct2d(\n                144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n              (bn2): BatchNormAct2d(\n                144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (aa): Identity()\n              (se): SqueezeExcite(\n                (conv_reduce): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n                (act1): ReLU(inplace=True)\n                (conv_expand): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n                (gate): Hardsigmoid()\n              )\n              (conv_pwl): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): BatchNormAct2d(\n                48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Identity()\n              )\n              (drop_path): Identity()\n            )\n          )\n          (4): Sequential(\n            (0): InvertedResidual(\n              (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): BatchNormAct2d(\n                288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (conv_dw): Conv2dSame(288, 288, kernel_size=(5, 5), stride=(2, 2), groups=288, bias=False)\n              (bn2): BatchNormAct2d(\n                288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (aa): Identity()\n              (se): SqueezeExcite(\n                (conv_reduce): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n                (act1): ReLU(inplace=True)\n                (conv_expand): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n                (gate): Hardsigmoid()\n              )\n              (conv_pwl): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): BatchNormAct2d(\n                96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Identity()\n              )\n              (drop_path): Identity()\n            )\n            (1): InvertedResidual(\n              (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): BatchNormAct2d(\n                576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n              (bn2): BatchNormAct2d(\n                576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (aa): Identity()\n              (se): SqueezeExcite(\n                (conv_reduce): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n                (act1): ReLU(inplace=True)\n                (conv_expand): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n                (gate): Hardsigmoid()\n              )\n              (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): BatchNormAct2d(\n                96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Identity()\n              )\n              (drop_path): Identity()\n            )\n            (2): InvertedResidual(\n              (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): BatchNormAct2d(\n                576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n              (bn2): BatchNormAct2d(\n                576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (aa): Identity()\n              (se): SqueezeExcite(\n                (conv_reduce): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n                (act1): ReLU(inplace=True)\n                (conv_expand): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n                (gate): Hardsigmoid()\n              )\n              (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): BatchNormAct2d(\n                96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Identity()\n              )\n              (drop_path): Identity()\n            )\n          )\n          (5): Sequential(\n            (0): ConvBnAct(\n              (conv): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): BatchNormAct2d(\n                576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n                (drop): Identity()\n                (act): Hardswish()\n              )\n              (aa): Identity()\n              (drop_path): Identity()\n            )\n          )\n        )\n      )\n    )\n    (decoder): UnetPlusPlusDecoder(\n      (center): Identity()\n      (blocks): ModuleDict(\n        (x_0_0): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(624, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_0_1): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(304, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_1_1): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(72, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_0_2): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(176, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_1_2): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(56, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_2_2): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(40, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_0_3): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_1_3): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_2_3): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(48, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_3_3): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_0_4): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n      )\n    )\n    (segmentation_head): SegmentationHead(\n      (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): Identity()\n      (2): Activation(\n        (activation): Identity()\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":12},{"id":"56a8c012","cell_type":"code","source":"! qai-hub configure --api_token f4840767cb173bbf00ee11945958efe528d14c63\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T17:31:08.998676Z","iopub.execute_input":"2025-04-06T17:31:08.998956Z","iopub.status.idle":"2025-04-06T17:31:09.662398Z","shell.execute_reply.started":"2025-04-06T17:31:08.998935Z","shell.execute_reply":"2025-04-06T17:31:09.661346Z"}},"outputs":[{"name":"stdout","text":"qai-hub configuration saved to /root/.qai_hub/client.ini\n==================== /root/.qai_hub/client.ini ====================\n[api]\napi_token = f4840767cb173bbf00ee11945958efe528d14c63\napi_url = https://app.aihub.qualcomm.com\nweb_url = https://app.aihub.qualcomm.com\nverbose = True\n\n\n","output_type":"stream"}],"execution_count":13},{"id":"0e9516b8","cell_type":"code","source":"# ---------------------------\n# Trace the model\n# ---------------------------\nexample_input = torch.rand((1, 3, 480, 640))\ntraced_model = torch.jit.trace(unet_model, example_input)\n\n# ---------------------------\n# Compile with AI Hub\n# ---------------------------\ndevice = hub.Device(\"Samsung Galaxy S24 (Family)\")\n\ncompile_job = hub.submit_compile_job(\n    name='unetplusplus_depth_estimation',\n    model=traced_model,\n    device=device,\n    input_specs={\"image\": (1, 3, 480, 640)}\n)\n\nprint(\"⏳ Compiling model...\")\ncompile_job.wait()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T17:34:44.638626Z","iopub.execute_input":"2025-04-06T17:34:44.638934Z","iopub.status.idle":"2025-04-06T17:34:47.606516Z","shell.execute_reply.started":"2025-04-06T17:34:44.638911Z","shell.execute_reply":"2025-04-06T17:34:47.605349Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-dc8da25b7315>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# ---------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Example placeholder if you're using Samsung AI Hub or similar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msamsung_ai_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m  \u001b[0;31m# Only if applicable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mdevice_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Samsung Galaxy S24 (Family)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'samsung_ai_hub'"],"ename":"ModuleNotFoundError","evalue":"No module named 'samsung_ai_hub'","output_type":"error"}],"execution_count":15},{"id":"d48e9615","cell_type":"code","source":"# Download compiled artifacts\ncompile_job.download_results(artifacts_dir=\"./compile_job_results\")\ncompiled_model = compile_job.get_target_model()","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["job_j5qeqy4m5_optimized_tflite_mnjlk6dxq.tflite: 100%|\u001b[34m██████████\u001b[0m| 185M/185M [00:12<00:00, 15.5MB/s] \n"]},{"name":"stdout","output_type":"stream","text":["Downloaded model to e:\\College\\S6\\CV\\indoor-monocular-depth-estimation\\unet-plus-plus-depth\\compile_job_results\\job_j5qeqy4m5_optimized_tflite_mnjlk6dxq.tflite\n"]}],"execution_count":5},{"id":"ada37025","cell_type":"code","source":"# ---------------------------\n# Profile the compiled model\n# ---------------------------\nprofile_job = hub.submit_profile_job(\n    name='unetplusplus_depth_profile',\n    model=compiled_model,\n    device=device\n)\n\nprint(\"⏳ Profiling on device...\")\nprofile_job.wait()\nprofile_job.download_results(artifacts_dir=\"./profile_job_results\")","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Scheduled profile job (j56e47o7g) successfully. To see the status and results:\n","    https://app.aihub.qualcomm.com/jobs/j56e47o7g/\n","\n","⏳ Profiling on device...\n","Waiting for profile job (j56e47o7g) completion. Type Ctrl+C to stop waiting at any time.\n","    ✅ SUCCESS                          \u0007\n","Saved profile results to e:\\College\\S6\\CV\\indoor-monocular-depth-estimation\\unet-plus-plus-depth\\profile_job_results\\unetplusplus_depth_profile_j56e47o7g_results.json\n"]},{"data":{"text/plain":["ProfileJobResult\n","----------------\n","status                        : JobStatus\n","---------\n","code    : SUCCESS\n","message : \n","\n","url                           : https://app.aihub.qualcomm.com/jobs/j56e47o7g/\n","artifacts_dir                 : e:\\College\\S6\\CV\\indoor-monocular-depth-estimation\\unet-plus-plus-depth\\profile_job_results\n","Estimated Inference Time (ms) : 60.711\n","Load Time (ms)                : 10844.763\n","Peak Memory (MB)              : 743.68359375\n","Compute Units (layers)        : NPU: 121"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"execution_count":6},{"id":"36b6991b","cell_type":"code","source":"profile_result = profile_job.download_profile()\nprint(\"\\n✅ Profile Job Completed!\")\nprint(f\"📄 Name: {profile_job.name}\")\nprint(f\"📱 Target Device: {profile_job.device.name}\")","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","✅ Profile Job Completed!\n","📄 Name: unetplusplus_depth_profile\n","📱 Target Device: Samsung Galaxy S24 (Family)\n"]}],"execution_count":12},{"id":"98f0dd14","cell_type":"code","source":"# # ---------------------------\n# # Run Inference on Test Images\n# # ---------------------------\n# transform = T.Compose([\n#     T.Resize((480, 640)),\n#     T.ToTensor()\n# ])\n\n# def load_image(path):\n#     img = Image.open(path).convert('RGB')\n#     return transform(img).unsqueeze(0)\n\n# def save_depth_map(depth, output_path):\n#     depth_np = depth.squeeze().detach().cpu().numpy()\n#     plt.imsave(output_path, depth_np, cmap='inferno')\n\n# # Load test images\n# test_dir = '../test_data/indoor'\n# test_images = [os.path.join(test_dir, f) for f in os.listdir(test_dir) if f.endswith(('.jpg', '.png'))]\n# os.makedirs(\"depth_predictions\", exist_ok=True)\n\n# for i, img_path in enumerate(test_images):\n#     img_tensor = load_image(img_path)\n#     with torch.no_grad():\n#         pred = unet_model(img_tensor)\n#         save_path = f\"depth_predictions/depth_{i+1}.png\"\n#         save_depth_map(pred, save_path)\n\n# print(f\"\\n🖼️ Saved {len(test_images)} predicted depth maps to 'depth_predictions/' folder.\")","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","🖼️ Saved 100 predicted depth maps to 'depth_predictions/' folder.\n"]}],"execution_count":null},{"id":"e028c4b2","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}